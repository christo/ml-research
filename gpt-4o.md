
# Notes on May 2024 GPT-4o Spoken Demos

## Personality, Tone and Cultural Refinement

To my Australian ear these demos exhibit tone mismatched with conventions in my familiar culture to the point of causing distraction, mild discomfort, even mistrust. This feels more creepy than if a human acted the same way because typically when a human does so, they are signialing a consistent culturally-contextualised personality, capacity and politics. Most people appear to be capable of restraining overly judgemental reactions until they have formed a detailed picture of a person's personal story. Being a foreigner while travelling, I have experienced "getting a pass" because I am not expected to better know behaviour that would be expected of a local. But does Chat GPT have a personality, culture of origin and life story or does its capacity to be a chameleon disable the valuable cues people are accustomed to using for understanding subtext, motive, trustworthiness and authenticity?

Excess flirtation has been widely discussed on the internet. It seems as though this is only one example of a range of tonal communicative behaviours that are typically assessed by people when they interact with each other. Chat GPT-4o in the demo videos features the following behaviours where expectations drive interpersonal interactions.

* opaque personality/identity modes - there is no signaled context for the agent's apparent ability to switch arbitrary personality traits
* sycophantic or excessively obsequious - raising suspicion that the agent has indiscriminate judgement or is attempting to inauthentically gain favour
* excess preference for encouragement at the expense of expected frankness or honesty - this is something that is very clearly localised to regional cultures
* inconsistent vulcanesque detachment - consistency would be a possible design goal to remind the human this is a robot but it seems at odds with OpenAI's aspirations
* misplaced authorative tone (given the widely known incidence of hallucination)
* sudden general tone deafness (when the surface signals of an agent are of a sophisticated person, a more stringent set of expectations are likely

We are a long way down the path of having AI agents that earn trust using the same process that like-minded strangers seek to do.

However, humans have certain important constraints that help people understand them:

* Humans have a coherent life timeline which informs their cultural sensibilities and makes them learnable for other humans. When interacting with a person, we try to get a sense of what they know, the language they use and their likely reference points. Being inconsisent in these dimensions raises a lot of red flags. Perhaps the solution is that an agent system hosts many, even thousands, of personalities that have a coherent personality and cultural reference points. It seems to be a goal that future agents will learn and attune to individual users and remember long-term context about past interactions. They might ask how the kids are doing, remember planned events and know not only the user's preferences but also their skills and interests. It seems like there are ever more uncanny valleys over the horizon. Perhaps they are objectively smaller but if human expectations rise, they could become the focus of consumer product preferences.
* Humans empathically detect when it is not their place to advise, correct or assume common ground. Especially across cultures and latent class divides, well meaning priviledged people misstep when they assume their empathy encompasses the experience of a less fortunate person. Humans with deep knowledge are also expected to remain humble on certain occasions and to be bold and forthright in others. These are subtle alignment parameters that have been discussed in AI Safety research but the interface with agents to engage and persist certain customisations may be expected by human users to work the same way it does with people. The scenario of an interaction can be defined as concentric prompt contexts. Going to the doctor, job interview or courtroom testimony all imply important constraints that sensible adults learn. If AI agents wish to be attributed person-like contexts, sensitivity to consequences arising from tone, manners etc. will be necessary to have a single model that can meet human expectations in a courtroom just as well as a poetry slam.



